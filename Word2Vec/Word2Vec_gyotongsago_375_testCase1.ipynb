{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jongil Park\\AppData\\Local\\conda\\conda\\envs\\python_study\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from konlpy.tag import Komoran;\n",
    "k = Komoran()   #TODO: Q.코모란 사용 이유?\n",
    "import nltk   #TODO: Q.nltk란 무엇인가?\n",
    "from nltk import FreqDist  # FreqDist 클래스는 문서에 사용된 단어(토큰)의 사용빈도 정보를 담는 클래스\n",
    "import pandas as pd\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫번째 테스트 케이스\n",
    "- '교통사고'키워드로 검색한 판례 375개를 Word2Vec 모델의 데이터 셋으로 활용한 테스트 케이스1.\n",
    "\n",
    "두번째 테스트 케이스(2271개 판례 활용)\n",
    "- 5개의 카테고리(교통사고, 교통, 사고, 운전, 차량)를 사용하여 Word2Vec 모델의 데이터 셋으로 활용한 테스트 케이스2.\n",
    "\n",
    "\n",
    "이 코드는 첫번째 테스트 케이스의 내용으로 구성하였습니다.\n",
    "\n",
    "데이터 전처리 작업 및 \n",
    "사용자의 입력값(Ex. 도로에서 음주 후 음주운전 중에 사고가 났고, 당시 알콜 농도는 0.15였습니다)을 토크나이징하여\n",
    "단어값들과 가장 연관성이 높은 Word2Vec모델의 값을 이용할 예정이며, 그 값이 높을수록 해당 판례와 관련성이 많다고 가정하였습니다.\n",
    "때문에 각 판례들을 각각 파싱하여 단어 구성과 단어의 갯수를 딕셔너리로 구성합니다 - \"1차 완료\"부분\n",
    "\n",
    "'교통사고'판례에서 나온 단어들을 토크나이징하고 그 중 사용할 단어와 사용하지 않을 단어 셋을 구성하였고,\n",
    "사용하지 않을 단어를 제외한 Word2Vec모델에 넣을 단어 말뭉치를 구성하였습니다 - \"2차 완료\"부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1차 완료: 각 타이틀, 사건번호, 딕셔너리(단어: 번호)매칭\n"
     ]
    }
   ],
   "source": [
    "# 1차적으로 사용하지 않을 키워드, 판례에서 필요한 부분(판례 제목, 사건 번호 등을 따로 뽑아 놓음)\n",
    "fileName_dnusing_wordSet = 'C:/Users/Jongil Park/PycharmProjects/ai_study/New_projectDirectory_law2' \\\n",
    "                           '/DataSet/Gyotongsago_data_375/Gyotongsago_dataSet/Gyotongsago_dnUsingWordSet_375_onlyNoun.txt'\n",
    "fileName_title = 'C:/Users/Jongil Park/PycharmProjects/ai_study/New_projectDirectory_law2' \\\n",
    "                 '/DataSet/Gyotongsago_data_375/Gyotongsago_dataSet/Gyotongsago_lawTitle_375.txt'\n",
    "fileName_keyNum = 'C:/Users/Jongil Park/PycharmProjects/ai_study/New_projectDirectory_law2' \\\n",
    "                  '/DataSet/Gyotongsago_data_375/Gyotongsago_dataSet/Gyotongsago_lawNumber_375.txt'\n",
    "\n",
    "## 불러온 파일 리스트화\n",
    "## TODO: Q.word_list를 나눈 기준은 무엇인가? 그것을 사람의 기준으로 나누고 시작하는 것이 과연 올바른 word2vec을 위한 전처리인가?\n",
    "with open(fileName_dnusing_wordSet, 'r') as infile:\n",
    "    word_list = [line.rstrip() for line in infile]\n",
    "\n",
    "## 타이틀만 모아놓은 것 리스트로 만들기\n",
    "with open(fileName_title, 'r') as infile2:\n",
    "    title_list = [line.rstrip() for line in infile2]\n",
    "\n",
    "## 키워드 넘버만 모아놓은 것 리스트 만들기\n",
    "# 왜 이부분에서 오류가 나는 것인지, 이유가 무엇인지 알고 있는가?\n",
    "try:\n",
    "    with open(fileName_keyNum) as infile3:\n",
    "        keyNum_list = [line.rstrip() for line in infile3]\n",
    "except UnicodeDecodeError:   ## TODO: 텍스트 파일을 불러올 때, 에러가 나는 이유는 무엇인가? 왜 그래서 codecs를 써야 하는가?\n",
    "    with codecs.open(fileName_keyNum, \"r\", \"utf-8\") as infile3:\n",
    "        keyNum_list = [line.rstrip() for line in infile3]\n",
    "\n",
    "\n",
    "## 여기서 pasing 된 corpus 값을 명사만 추출하여 각 단어별 갯수를 딕셔너리로 만들어주고 append\n",
    "## TODO: 과연 이 데이터에서 명사만을 추출하는 것이 올바른 접근법인가? 이것으로 명사들과의 관계나 유사도를 올바르게 판단할 수 있는가?\n",
    "def append_noun_words(corpus):\n",
    "    noun_words = ['NNG', 'NNB', 'NP']  # 일반명사, 고유명사, 대명사만 학습  // 이렇게 한 이유에 대해서?\n",
    "    results = []\n",
    "    for text in corpus:\n",
    "        for noun_word in noun_words:\n",
    "            if noun_word in text[1]:\n",
    "                results.append(text[0])\n",
    "    return results\n",
    "\n",
    "## {판례의 명사 키워드의 단어:갯수 매칭된 리스트}\n",
    "total_panrye_parsingReason = []  # 이 안의 값은 딕셔너리가 되어야 함\n",
    "\n",
    "## Gyotongsago 하나의 카테고리만 활용할 때,\n",
    "file_name = ['C:/Users/Jongil Park/PycharmProjects/ai_study/New_projectDirectory_law2/DataSet/Gyotongsago_data_375'\n",
    "             '/Gyotongsago_dataSet/Gyotongsago_reason_375/({0}).txt']\n",
    "file_len = [375]\n",
    "\n",
    "\"\"\" 5개의 카테고리(교통사고, 교통, 사고, 운전, 차량) 모두 사용할 때,\n",
    "file_name = ['C:/Users/Jongil Park/PycharmProjects/ai_study/New_projectDirectory_law2/DataSet/Total_gyotongsago_data_2271'\n",
    "             '/Total_gyotongsago_dataSet/Total_gyotongsago_eachReason_2000/(1)_Gyotongsago/({0}).txt',\n",
    "            'C:/Users/Jongil Park/PycharmProjects/ai_study/New_projectDirectory_law2/DataSet/Total_gyotongsago_data_2271'\n",
    "             '/Total_gyotongsago_dataSet/Total_gyotongsago_eachReason_2000/(2)_Gyotong/({0}).txt',\n",
    "            'C:/Users/Jongil Park/PycharmProjects/ai_study/New_projectDirectory_law2/DataSet/Total_gyotongsago_data_2271'\n",
    "             '/Total_gyotongsago_dataSet/Total_gyotongsago_eachReason_2000/(3)_sago/({0}).txt',\n",
    "            'C:/Users/Jongil Park/PycharmProjects/ai_study/New_projectDirectory_law2/DataSet/Total_gyotongsago_data_2271'\n",
    "             '/Total_gyotongsago_dataSet/Total_gyotongsago_eachReason_2000/(4)_Unjeon/({0}).txt',\n",
    "            'C:/Users/Jongil Park/PycharmProjects/ai_study/New_projectDirectory_law2/DataSet/Total_gyotongsago_data_2271'\n",
    "             '/Total_gyotongsago_dataSet/Total_gyotongsago_eachReason_2000/(5)_Charyang/({0}).txt']\n",
    "file_len = [375, 956, 382, 329, 229]  ## TODO: 과연 텍스트 파일에서 전체 길이를 파악할 수 있도록 하려면 어떻게 해야할까?\n",
    "\"\"\"\n",
    "\n",
    "for z in range(len(file_name)):\n",
    "\n",
    "    for i in range(file_len[z]):    # len(title_list)\n",
    "        ione_panrye_parsingReason = {}\n",
    "\n",
    "        # TODO: 특정 처리를 하면 try catch 문장을 쓰지 않아도 될 듯. 텍스트 데이터에 맞는 정규표현식으로 바꾼다면 말이다.\n",
    "        try:\n",
    "            with open(file_name[z].format(i+1), 'r') as f:\n",
    "                texts = f.read()\n",
    "                corpus = k.pos(\"\\n\".join([s for s in texts.split(\"\\n\") if s]))\n",
    "        except UnicodeDecodeError:\n",
    "            with codecs.open(file_name[z].format(i+1), \"r\", \"utf-8\") as f:\n",
    "                texts = f.read()\n",
    "                corpus = k.pos(\"\\n\".join([s for s in texts.split(\"\\n\") if s]))\n",
    "\n",
    "        corpus = append_noun_words(corpus)\n",
    "        corpus_ko = nltk.Text(corpus, name=\"각 판례별 명사 처리\")\n",
    "        corpus_ko_vocab = corpus_ko.vocab()\n",
    "        ## 여기서 이미 most_common으로 순서를 정해주고 있는데, 이것은 옳지 않은듯\n",
    "        corpus_vocab_common = corpus_ko_vocab.most_common(len(corpus_ko_vocab))\n",
    "\n",
    "    ## 여기에 필요한 키워드 값만 추출하는 것을 추가 할 것.\n",
    "        for j in range(len(corpus_vocab_common)):\n",
    "            if corpus_vocab_common[j][0] not in word_list:\n",
    "                ione_panrye_parsingReason[corpus_vocab_common[j][0]] = corpus_vocab_common[j][1]\n",
    "        total_panrye_parsingReason.append(ione_panrye_parsingReason)\n",
    "\n",
    "print(\"1차 완료: 각 타이틀, 사건번호, 딕셔너리(단어: 번호)매칭\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec 전, 2차 완료\n",
      "len(total_sumWord):  63352\n"
     ]
    }
   ],
   "source": [
    "#======================================================================================================\n",
    "## TODO: 3번: W2V을 위한 데이터 전처리, '기준'을 어떻게 둘 것인가?\n",
    "\"\"\"최종적으로 데이터 프레임화를 위한 리스트\"\"\"\n",
    "# 학습데이터 sum 값 - 5개 합치기\n",
    "\"\"\"'교통사고' 판례에서 '이유'부분이 의미가 있다고 생각하여 판례를 전처리 해놓은 데이터를 사용\n",
    "과연 각 키워드(Ex.'교통'...)별 판례의 합으로 전체 단어를 추출하고 그것을 W2V 모델에 넣는 것이 맞을까?\n",
    "혹은 각 판례를 W2V 모델에 넣고 거기서 나온 벡터값이나 키워드 유사성을 합치거나 조절하는 것이 맞을까?\n",
    "만약 각 판례의 값을 활용한다면 그것의 벡터값의 단순합이 의미가 있진 않을 것 같은데, 기본 데이터를 어떻게 W2V모델에 넣어야 할까? \n",
    "\"\"\"\n",
    "# TODO: 판례 데이터 사용방법 1. '교통사고'의 이유 부분 전체 합을 이용 / 2. '교통사고' 각 판례(375개)를 각각 W2V 모델에 사용하고 그 값들을 활용?\n",
    "\n",
    "# 각 교통사고 관련 카테고리의 '이유' 부분의 sum 값을 활용\n",
    "data_file = ['C:/Users/Jongil Park/PycharmProjects/ai_study/New_projectDirectory_law2/DataSet/Gyotongsago_data_375'\n",
    "             '/Gyotongsago_dataSet/Gyotongsago_totalSum_375.txt']\n",
    "\n",
    "\"\"\" 교통사고 관련 카테고리(교튱사고, 교통, 사고, 운전, 차량) 5개 판례 - 2271개 모두 활용을 위한\n",
    "data_file = ['C:/Users/Jongil Park/PycharmProjects/ai_study/New_projectDirectory_law2/DataSet/Total_gyotongsago_data_2271/'\n",
    "             'Total_gyotongsago_dataSet/Total_gyotongsago_sumReason_5/(1)_Gyotongsago.txt',\n",
    "             'C:/Users/Jongil Park/PycharmProjects/ai_study/New_projectDirectory_law2/DataSet/Total_gyotongsago_data_2271/'\n",
    "             'Total_gyotongsago_dataSet/Total_gyotongsago_sumReason_5/(2)_Gyotong.txt',\n",
    "             'C:/Users/Jongil Park/PycharmProjects/ai_study/New_projectDirectory_law2/DataSet/Total_gyotongsago_data_2271/'\n",
    "             'Total_gyotongsago_dataSet/Total_gyotongsago_sumReason_5/(3)_Sago.txt',\n",
    "             'C:/Users/Jongil Park/PycharmProjects/ai_study/New_projectDirectory_law2/DataSet/Total_gyotongsago_data_2271/'\n",
    "             'Total_gyotongsago_dataSet/Total_gyotongsago_sumReason_5/(4)_Unjeon.txt',\n",
    "             'C:/Users/Jongil Park/PycharmProjects/ai_study/New_projectDirectory_law2/DataSet/Total_gyotongsago_data_2271/'\n",
    "             'Total_gyotongsago_dataSet/Total_gyotongsago_sumReason_5/(5)_Charyang.txt']\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "total_sumWord를 하는 과정에서 '교통사고'하나만 했을 때는 단어 순서가 그 하나의 범위내에서 하기 때문에 상관없지만\n",
    "5개의 카테고리를 모두 합한 단어 말뭉치를 활용할 경우, '교통사고' + '교통'이 아무 제약없이 연결되면서 상관관계가 약해지거나 \n",
    "없어질듯. 즉, 만약 5개의 카테고리를 한다면, 각 카테고리의 W2V값을 추후에 합하던가 하는 방법으로 활용해야 할 듯. \n",
    "처음부터 5개의 카테고리의 모든 단어를 하나의 W2V모델로 활용하면 위와 같은 문제('교통사고' 마지막 키워드, '교통' 맨 앞 키워드의 \n",
    "연관성이 갑자기 생기는 것과 같다)가 발생.\n",
    "\"\"\"\n",
    "\n",
    "total_sumWord = []\n",
    "for i in range(len(data_file)):\n",
    "    try:\n",
    "        with open(data_file[i]) as f:\n",
    "            texts = f.read()\n",
    "            corpus = k.pos(\"\\n\".join([s for s in texts.split(\"\\n\") if s]))  # 이것의 의미 다시 한번 생각\n",
    "\n",
    "    except UnicodeDecodeError:\n",
    "        with codecs.open(data_file[i], \"r\", \"utf-8\") as f:\n",
    "            texts = f.read()\n",
    "            corpus = k.pos(\"\\n\".join([s for s in texts.split(\"\\n\") if s]))\n",
    "\n",
    "    corpus = append_noun_words(corpus)\n",
    "    corpus_ko = nltk.Text(corpus, name=\"각 판례별 명사 처리\")\n",
    "    corpus_ko_vocab = corpus_ko.vocab()\n",
    "    corpus_ko_vocab_items = corpus_ko_vocab.items()\n",
    "    corpus_ko_vocab_items = list(corpus_ko_vocab_items)  ## TODO: 과연 items순이 옳을까?(아니라고 생각한다. 하지만 정말 옳은 방법에 대해 쉽게 감이 잡히지 않는다)\n",
    "    #corpus_vocab_common = corpus_ko_vocab.most_common(len(corpus_ko))\n",
    "    ##중요 TODO: 각 '이유'부분에서 2000개의 태깅된 명사들 추출에서, 순서를 유지한 상태에서, 각 이유를 각 차원으로 가진 상태에서\n",
    "    ##     TODO: 전체 n차원('이유'의 갯수만큼) 데이터를 Word2Vec모델에 넣는 것이 맞을듯. 지금은 전체 이유에서 나온 명사를 하나로 통합하여 전체 2차원으로 작업의 결과.\n",
    "\n",
    "    ## TODO: 전체 단어의 순서를 유지하지 않는다면 굳이 전체 데이터를 사용할 필요나 이유가 없지 않은가?\n",
    "    ## TODO: 그렇다면 전체 순서를 유지하면서 어떻게 우리가 원하는 올바른 유사도를 가진 데이터로 만들 수 있을까?\n",
    "\n",
    "    ## new_corpus 는 살릴 단어가 하나씩 밖에 안 들어가 있다. 그 개수가 빠져있는 합.\n",
    "    new_corpus = []\n",
    "    corpus_values = []\n",
    "    new_corpus2 = []\n",
    "\n",
    "    for z in range(len(corpus_ko_vocab_items)):\n",
    "        corpus_word = corpus_ko_vocab_items[z][0]\n",
    "        if corpus_word not in word_list:\n",
    "            new_corpus.append([corpus_word])\n",
    "            corpus_values.append(corpus_ko_vocab_items[z][1])\n",
    "    new_corpus2 = sum(new_corpus, [])\n",
    "\n",
    "    last_using_word = []\n",
    "    for j in range(len(new_corpus)):\n",
    "        last_using_word.append(''.join(new_corpus[j]))   # join => 리스트를 문자열로 합치기\n",
    "\n",
    "    \"\"\"\n",
    "    df3 = pd.DataFrame(corpus_values, index=last_using_word)\n",
    "    df3.to_excel(\"C:/Users/user/PycharmProjects/python_study/projectDirectory/POS&embedding/test_dataset/\" \\\n",
    "                 \"TOTAL_GYOTONGSAGO_DATA/TOTAL_GYOTONGSAGO_USING_WORD_LAST({0}).xlsx\".format(i+1),\n",
    "                 sheet_name='단어')\n",
    "    print(\"TOTAL_GYOTONGSAGO_USING_WORD_LAST 저장완료\")\n",
    "    \"\"\"\n",
    "    ## 이것이 corpus 에서 쓰지 않은 키워드를 갯수만큼 제외시키는 것\n",
    "    word_corpus_last = [x for x in corpus if x not in word_list]\n",
    "    word_corpus_last2 = []\n",
    "    for z in range(len(word_corpus_last)):\n",
    "        word_corpus_last2.append([word_corpus_last[z]])   # word_corpus_last2.append(word_corpus_last[z].split())에서 변경\n",
    "\n",
    "    total_sumWord.append(word_corpus_last2)\n",
    "    # total_sumWord.append(new_corpus)\n",
    "total_sumWord = sum(total_sumWord, [])\n",
    "df4 = pd.DataFrame(total_sumWord)\n",
    "df4.to_excel('C:/Users/Jongil Park/PycharmProjects/ai_study/New_projectDirectory_law2/DataSet/Gyotongsago_data_375/'\n",
    "             'Gyotongsago_resultSet/total_sumWord_for_W2V.xlsx',\n",
    "             sheet_name='최종W2V단어말뭉치')\n",
    "\n",
    "\"\"\"CSV파일로 저장 원할시,\n",
    "df4 = pd.DataFrame(total_sumWord)\n",
    "df4.to_csv('C:/Users/Jongil Park/PycharmProjects/ai_study/New_projectDirectory_law2/DataSet/Gyotongsago_data_375/'\n",
    "           'Gyotongsago_resultSet/total_sumWord_for_W2V(3).csv')\n",
    "\"\"\"\n",
    "## Word2Vec\n",
    "## 직접 Word2Vec 모델을 만들 수 있을까?\n",
    "print(\"word2vec 전, 2차 완료\")\n",
    "print(\"len(total_sumWord): \", len(total_sumWord))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최종 단어 말뭉치로 확보단 63352개의 단어 말뭉치 확보\n",
    "(각 단어의 중복 및 순서 혀용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(w2v_key): 596\n"
     ]
    }
   ],
   "source": [
    "word2vec_model = Word2Vec(total_sumWord, size=200,     # 인자값에 new_corpus 혹은 word_corpus_last2\n",
    "                          window=2,\n",
    "                          min_count=10,\n",
    "                          workers=4,\n",
    "                          iter=10000, sg=1)\n",
    "\n",
    "w2v_key = word2vec_model.wv.vocab.keys()\n",
    "input_keyword_last = ['테스트를 위한 빈값 넣어놓은 것']\n",
    "print(\"len(w2v_key):\", len(w2v_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색어를 입력하세요(끝내시려면 enter 키를 눌러주세요): 도로에서 음주 후 음주운전 중에 사고가 났고, 알콜 농도는 0.15였습니다\n",
      "len(predict_model):  596\n",
      "(1)차 구동완료\n",
      "검색어를 입력하세요(끝내시려면 enter 키를 눌러주세요): \n",
      "구동완료\n"
     ]
    }
   ],
   "source": [
    "def input_to_keyword():\n",
    "    input_text = input(\"검색어를 입력하세요(끝내시려면 enter 키를 눌러주세요): \")\n",
    "    k = Komoran()    # 새로 변수를 정의하지 않을시 반복해서 사용자가 검색어를 입력하면 에러가 뜨는 경우가 발생\n",
    "    if input_text is '':\n",
    "        input_keyword_last = None\n",
    "        return input_keyword_last\n",
    "    else:\n",
    "        input_corpus = k.pos(\"\\n\".join([s for s in input_text.split(\"\\n\") if s]))\n",
    "        parsed_input = append_noun_words(input_corpus)\n",
    "        input_keyword_last = []\n",
    "        for j in range(len(parsed_input)):\n",
    "            # if parsed_input[j] not in word_list:\n",
    "            # 위에 문장을 쓰지 않는 이유는 사용자가 검색한 키워드가 항상 우리 키워드 안에 있지는 않지만, 사용자의 키워드를 보여줄 필요는 있다.\n",
    "            input_keyword_last.append(parsed_input[j])\n",
    "        return input_keyword_last\n",
    "\n",
    "repeat_num = 1    # 저장할 액셀 파일에 숫자를 붙여주기 위한 기초값, 첫번째를 뜻함.\n",
    "\n",
    "while True:\n",
    "    input_keyword_last = input_to_keyword()  # 인풋값을 사용할 키워드로 정리한 값\n",
    "    if input_keyword_last is None:\n",
    "        break\n",
    "    columns_keyword = \"·\".join(input_keyword_last)  # 컬럼 이름을 위한 합치기\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    predict_words = []\n",
    "    predict_values = []\n",
    "\n",
    "    ## TODO: 과연 내가 찾으려고 하는 연관성이 predict_output_word()가 맞는가?\n",
    "    predict_model = word2vec_model.predict_output_word(input_keyword_last, topn=len(w2v_key))\n",
    "    for n in range(len(predict_model)):\n",
    "        predict_words.append((predict_model[n][0]))\n",
    "        predict_values.append(predict_model[n][1])\n",
    "    val_words = pd.Series(predict_words)\n",
    "    val_values = pd.Series(predict_values)\n",
    "    df[columns_keyword] = val_words\n",
    "    df['vector값'] = val_values\n",
    "    #word2vec_model.max_final_vocab  # 이것은 왜 필요한거지? 아마 그냥 들어간거 같은데!!??\n",
    "\n",
    "    df.to_csv('C:/Users/Jongil Park/PycharmProjects/ai_study/New_projectDirectory_law2/DataSet/Gyotongsago_data_375/Gyotongsago_resultSet'\n",
    "              '/Gyotongsago_375_W2V_predict({0}).csv'.format(repeat_num),\n",
    "              encoding='CP949')\n",
    "\n",
    "    print(\"len(predict_model): \", len(predict_model))\n",
    "    print(\"({0})차 구동완료\".format(repeat_num))\n",
    "\n",
    "    ## 키워드 연관 단어 상위 20개를 기준으로 한 카운트 값\n",
    "    df_top20 = df[columns_keyword].iloc[:20]   ## iloc와 loc 차이? 여기에선 같은 값이 나오지만 둘의 차이 명확히 알기\n",
    "    count_list_total = []\n",
    "    for kk in range(len(total_panrye_parsingReason)):\n",
    "        count = 0\n",
    "        for j in range(len(df_top20)):\n",
    "            if df_top20[j] in total_panrye_parsingReason[kk]:\n",
    "                # 현재 count 값은 상위 20개를 순서상관없이 + 값, 순서별로 가중치를 주는 방법도 고려할 것.\n",
    "                count += total_panrye_parsingReason[kk][df_top20[j]]\n",
    "        count_list_total.append(count)\n",
    "\n",
    "    # 카운트 값이 높은 순서의 인덱스 값의 리스트를 만들기\n",
    "    df_count = pd.DataFrame()\n",
    "    val_title_list = pd.Series(title_list)\n",
    "    val_keyNum_list = pd.Series(keyNum_list)\n",
    "\n",
    "    df_count = pd.DataFrame({(columns_keyword): count_list_total})\n",
    "    df_count['판례이름'] = val_title_list\n",
    "    df_count['사건번호'] = val_keyNum_list\n",
    "    last_df_count = df_count.sort_values(by=columns_keyword, ascending=False)\n",
    "\n",
    "    last_df_count.to_csv('C:/Users/Jongil Park/PycharmProjects/ai_study/New_projectDirectory_law2/DataSet'\n",
    "                         '/Gyotongsago_data_375/Gyotongsago_resultSet/Gyotongsago_375_W2V_result({0}).csv'.format(repeat_num),\n",
    "                         encoding='CP949')\n",
    "    repeat_num += 1\n",
    "\n",
    "print(\"구동완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>도로·음주·후·음주운전·중·사고·알콜·농도</th>\n",
       "      <th>vector값</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>피고인</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>반대편</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>취득</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>유인</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>차례</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>계약</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>앞쪽</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>청구</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>무시</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>공동정범</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>면허증</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>추락</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>손잡이</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>특별</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>감금</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>방어</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>대리</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>주변</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>집행유예</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>상호</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>연락</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>국도</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>협박</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>머리</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>성</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>손해</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>구분</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>특수</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>발급</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>골절상</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>손상</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>차체</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>면허</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>시작</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>다리</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>상처</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>처분</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>공소기각</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>보험금</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>승객</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>과속</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>보행</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>이익</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>성립</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>타이어</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>운전석</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>졸음</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>피의자신문</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>농도</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>기준</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>검출</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>신체</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>보험료</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>일방통행</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>급제동</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>일반</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>앞부분</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>경합</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>부당</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>유사</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>596 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    도로·음주·후·음주운전·중·사고·알콜·농도   vector값\n",
       "0                       피고인  0.001678\n",
       "1                       반대편  0.001678\n",
       "2                        취득  0.001678\n",
       "3                        유인  0.001678\n",
       "4                        차례  0.001678\n",
       "5                        계약  0.001678\n",
       "6                        앞쪽  0.001678\n",
       "7                        청구  0.001678\n",
       "8                        무시  0.001678\n",
       "9                      공동정범  0.001678\n",
       "10                      면허증  0.001678\n",
       "11                       추락  0.001678\n",
       "12                      손잡이  0.001678\n",
       "13                       특별  0.001678\n",
       "14                       감금  0.001678\n",
       "15                       방어  0.001678\n",
       "16                       대리  0.001678\n",
       "17                       주변  0.001678\n",
       "18                     집행유예  0.001678\n",
       "19                       상호  0.001678\n",
       "20                       연락  0.001678\n",
       "21                       국도  0.001678\n",
       "22                       협박  0.001678\n",
       "23                       머리  0.001678\n",
       "24                        성  0.001678\n",
       "25                       손해  0.001678\n",
       "26                       구분  0.001678\n",
       "27                       특수  0.001678\n",
       "28                       발급  0.001678\n",
       "29                      골절상  0.001678\n",
       "..                      ...       ...\n",
       "566                      손상  0.001678\n",
       "567                      차체  0.001678\n",
       "568                      면허  0.001678\n",
       "569                      시작  0.001678\n",
       "570                      다리  0.001678\n",
       "571                      상처  0.001678\n",
       "572                      처분  0.001678\n",
       "573                    공소기각  0.001678\n",
       "574                     보험금  0.001678\n",
       "575                      승객  0.001678\n",
       "576                      과속  0.001678\n",
       "577                      보행  0.001678\n",
       "578                      이익  0.001678\n",
       "579                      성립  0.001678\n",
       "580                     타이어  0.001678\n",
       "581                     운전석  0.001678\n",
       "582                      졸음  0.001678\n",
       "583                   피의자신문  0.001678\n",
       "584                      농도  0.001678\n",
       "585                      기준  0.001678\n",
       "586                      검출  0.001678\n",
       "587                      신체  0.001678\n",
       "588                     보험료  0.001678\n",
       "589                    일방통행  0.001678\n",
       "590                     급제동  0.001678\n",
       "591                      일반  0.001678\n",
       "592                     앞부분  0.001678\n",
       "593                      경합  0.001678\n",
       "594                      부당  0.001678\n",
       "595                      유사  0.001678\n",
       "\n",
       "[596 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용자의 입력이\n",
    "\"도로에서 음주 후 음주운전 중에 사고가 났고, 알콜 농도는 0.15였습니다.\"일 때,\n",
    "해당 입력값을 파싱하여 Word2Vec모델에 넣고 가장 연관성이 높다고(높은 벡터값) 나온 단어 셋을 만들었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>도로·음주·후·음주운전·중·사고·알콜·농도</th>\n",
       "      <th>판례이름</th>\n",
       "      <th>사건번호</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>245</td>\n",
       "      <td>폭력행위등 처벌에 관한 법률위반(공동공갈)·업무 방해·공갈·폭력행위등 처벌에 관한 ...</td>\n",
       "      <td>2011노163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>176</td>\n",
       "      <td>살인(예비적죄명:교통사고처리특례법위반)·사기</td>\n",
       "      <td>2015노358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>158</td>\n",
       "      <td>살인(예비적죄명:교통사고처리특례법위반)·사기(남편이 보험금을 노리고 교통사고를 내어...</td>\n",
       "      <td>2017도1549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>133</td>\n",
       "      <td>강도치상·특수강도·도로교통법위반(무면허운전)·사기·교통사고처리특례법위반</td>\n",
       "      <td>2006고합880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>131</td>\n",
       "      <td>폭력행위등 처벌에 관한 법률위반(공동 공갈)·업무 방해·공갈·폭력행위등 처벌에 관한...</td>\n",
       "      <td>2009고합613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>129</td>\n",
       "      <td>감금치사[선택적죄명:살인,인정된죄명:도로교통법위반(사고후미조치)·유기치사]</td>\n",
       "      <td>2013노2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>115</td>\n",
       "      <td>특정범죄가중처벌등에관한법률위반(도주차량)·교통사고처리특례법위반·도로교통법위반·도로교...</td>\n",
       "      <td>2006노2898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>101</td>\n",
       "      <td>강도치상(인정된죄명:절도·상해)·특수강도·도로교통법위반(무면허운전)·사기·교통사고처...</td>\n",
       "      <td>2007노193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>96</td>\n",
       "      <td>특정범죄가중처벌등에관한법률위반(영리약취·유인등)·아동·청소년의성보호에관한법률위반(강...</td>\n",
       "      <td>2011노573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>87</td>\n",
       "      <td>교통사고처리특례법위반</td>\n",
       "      <td>93노4273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>69</td>\n",
       "      <td>특정범죄가중처벌등에관한법률위반(도주차량, 인정된 죄명 : 교통사고처리특례법위반)</td>\n",
       "      <td>96도591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>51</td>\n",
       "      <td>특정범죄가중처벌등에관한법률위반(도주차량, 인정된 죄명 : 교통사고처리특례법위반)·도...</td>\n",
       "      <td>99도5023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>48</td>\n",
       "      <td>교통사고처리특례법위반</td>\n",
       "      <td>97도1702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>45</td>\n",
       "      <td>교통사고처리특례법위반</td>\n",
       "      <td>98도2605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>44</td>\n",
       "      <td>교통사고처리특례법위반ㆍ업무상과실자동차파괴</td>\n",
       "      <td>83도3006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>44</td>\n",
       "      <td>사기·교통사고처리특례법위반·유가증권위조(변경된죄명:유가증권변조)·위조유가증권행사(변...</td>\n",
       "      <td>2005노396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>44</td>\n",
       "      <td>살인·폭력행위등처벌에관한법률위반·특수공무집행방해치상·공용물건손상·도로교통법위반·향정...</td>\n",
       "      <td>96도2588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>42</td>\n",
       "      <td>교통사고처리특례법위반·도로교통법위반(음주운전)</td>\n",
       "      <td>2006노1642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>41</td>\n",
       "      <td>교통사고처리특례법위반·도로교통법위반</td>\n",
       "      <td>96도1540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>39</td>\n",
       "      <td>교통사고처리특례법위반</td>\n",
       "      <td>92도934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>39</td>\n",
       "      <td>폭력행위등처벌에관한법률위반(야간·공동상해)·공무집행방해·교통사고처리특례법위반·도로교...</td>\n",
       "      <td>2004고단232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>39</td>\n",
       "      <td>교통사고처리특례법위반</td>\n",
       "      <td>2007노187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>38</td>\n",
       "      <td>교통사고처리특례법위반피고사건</td>\n",
       "      <td>84노95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>37</td>\n",
       "      <td>교통사고처리특례법위반</td>\n",
       "      <td>2008노6114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>37</td>\n",
       "      <td>특정범죄가중처벌등에관한법률위반(도주차량)(인정된 죄명 : 교통사고처리특례법위반)·도...</td>\n",
       "      <td>2000노1145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>37</td>\n",
       "      <td>교통사고처리특례법위반</td>\n",
       "      <td>96도1198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>35</td>\n",
       "      <td>교통사고처리특례법위반·도로교통법위반</td>\n",
       "      <td>2004고정1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>34</td>\n",
       "      <td>교통 사고 처리 특례법 위반</td>\n",
       "      <td>2011노2629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>34</td>\n",
       "      <td>교통사고처리특례법위반</td>\n",
       "      <td>89도377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>33</td>\n",
       "      <td>교통사고 처리 특례법 위반</td>\n",
       "      <td>2011노938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>교통사고처리특례법위반</td>\n",
       "      <td>92도2077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>1</td>\n",
       "      <td>교통사고처리특례법위반</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1</td>\n",
       "      <td>교통사고처리특례법위반</td>\n",
       "      <td>86도325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>1</td>\n",
       "      <td>교통사고처리특례법위반</td>\n",
       "      <td>90도761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>1</td>\n",
       "      <td>교통사고처리특례법위반</td>\n",
       "      <td>87도2173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>1</td>\n",
       "      <td>교통사고 처리 특례법 위반</td>\n",
       "      <td>2011도3970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1</td>\n",
       "      <td>교통사고처리특례법위반</td>\n",
       "      <td>84도2651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>1</td>\n",
       "      <td>교통사고처리특례법위반</td>\n",
       "      <td>88도632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1</td>\n",
       "      <td>교통사고처리특례법위반</td>\n",
       "      <td>86도2514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>1</td>\n",
       "      <td>교통사고처리특례법위반</td>\n",
       "      <td>96도690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>도로교통법위반(음주운전)·교통사고처리특례법위반</td>\n",
       "      <td>2005고정765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>교통사고처리특례법위반·도로교통법위반(음주운전)·도로교통법위반(무면허운전)</td>\n",
       "      <td>2013도15031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>1</td>\n",
       "      <td>교통사고처리특례법위반,도로교통법위반</td>\n",
       "      <td>89도1792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>1</td>\n",
       "      <td>교통사고처리특례법위반</td>\n",
       "      <td>90도2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1</td>\n",
       "      <td>교통사고처리특례법위반</td>\n",
       "      <td>2005고단20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1</td>\n",
       "      <td>교통사고처리특례법위반</td>\n",
       "      <td>84도182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>1</td>\n",
       "      <td>중대한교통사고차량면허취소처분취소</td>\n",
       "      <td>89누3564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>1</td>\n",
       "      <td>교통사고처리특례법위반</td>\n",
       "      <td>89도1696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>교통사고처리특례법위반</td>\n",
       "      <td>88도2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0</td>\n",
       "      <td>특정범죄가중처벌등에관한법률위반(도주차량),교통사고처리특례법위반</td>\n",
       "      <td>88도1399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>도로교통법위반(사고후미조치)·도로교통법위반(음주운전)</td>\n",
       "      <td>2015도12451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0</td>\n",
       "      <td>교통사고처리특례법위반</td>\n",
       "      <td>85도1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>0</td>\n",
       "      <td>특정범죄가중처벌등에관한법률위반(위험운전치사상)(인정된죄명:교통사고처리특례법위반)·도...</td>\n",
       "      <td>2009고정2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0</td>\n",
       "      <td>교통사고처리특례법위반</td>\n",
       "      <td>2003도1895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0</td>\n",
       "      <td>교통사고처리특례법위반</td>\n",
       "      <td>86도1868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0</td>\n",
       "      <td>교통사고처리특례법위반</td>\n",
       "      <td>85도1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>교통사고처리특례법위반</td>\n",
       "      <td>2007도1808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>교통사고처리특례법위반</td>\n",
       "      <td>2006고정4418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0</td>\n",
       "      <td>교통사고처리특례법위반등피고사건</td>\n",
       "      <td>84고단1070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>0</td>\n",
       "      <td>교통사고처리특례법위반,도로교통법위반</td>\n",
       "      <td>92도1602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>375 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     도로·음주·후·음주운전·중·사고·알콜·농도  \\\n",
       "354                      245   \n",
       "36                       176   \n",
       "12                       158   \n",
       "86                       133   \n",
       "353                      131   \n",
       "373                      129   \n",
       "15                       115   \n",
       "85                       101   \n",
       "340                       96   \n",
       "301                       87   \n",
       "290                       69   \n",
       "90                        51   \n",
       "287                       48   \n",
       "293                       45   \n",
       "129                       44   \n",
       "76                        44   \n",
       "281                       44   \n",
       "57                        42   \n",
       "286                       41   \n",
       "310                       39   \n",
       "52                        39   \n",
       "87                        39   \n",
       "60                        38   \n",
       "332                       37   \n",
       "29                        37   \n",
       "275                       37   \n",
       "53                        35   \n",
       "358                       34   \n",
       "221                       34   \n",
       "346                       33   \n",
       "..                       ...   \n",
       "25                         1   \n",
       "204                        1   \n",
       "175                        1   \n",
       "238                        1   \n",
       "203                        1   \n",
       "343                        1   \n",
       "149                        1   \n",
       "207                        1   \n",
       "194                        1   \n",
       "273                        1   \n",
       "54                         1   \n",
       "5                          1   \n",
       "222                        1   \n",
       "242                        1   \n",
       "84                         1   \n",
       "130                        1   \n",
       "223                        1   \n",
       "225                        1   \n",
       "19                         1   \n",
       "211                        0   \n",
       "7                          0   \n",
       "177                        0   \n",
       "321                        0   \n",
       "102                        0   \n",
       "191                        0   \n",
       "193                        0   \n",
       "48                         0   \n",
       "56                         0   \n",
       "62                         0   \n",
       "311                        0   \n",
       "\n",
       "                                                  판례이름        사건번호  \n",
       "354  폭력행위등 처벌에 관한 법률위반(공동공갈)·업무 방해·공갈·폭력행위등 처벌에 관한 ...    2011노163  \n",
       "36                            살인(예비적죄명:교통사고처리특례법위반)·사기    2015노358  \n",
       "12   살인(예비적죄명:교통사고처리특례법위반)·사기(남편이 보험금을 노리고 교통사고를 내어...   2017도1549  \n",
       "86             강도치상·특수강도·도로교통법위반(무면허운전)·사기·교통사고처리특례법위반   2006고합880  \n",
       "353  폭력행위등 처벌에 관한 법률위반(공동 공갈)·업무 방해·공갈·폭력행위등 처벌에 관한...   2009고합613  \n",
       "373          감금치사[선택적죄명:살인,인정된죄명:도로교통법위반(사고후미조치)·유기치사]   2013노2492  \n",
       "15   특정범죄가중처벌등에관한법률위반(도주차량)·교통사고처리특례법위반·도로교통법위반·도로교...   2006노2898  \n",
       "85   강도치상(인정된죄명:절도·상해)·특수강도·도로교통법위반(무면허운전)·사기·교통사고처...    2007노193  \n",
       "340  특정범죄가중처벌등에관한법률위반(영리약취·유인등)·아동·청소년의성보호에관한법률위반(강...    2011노573  \n",
       "301                                        교통사고처리특례법위반     93노4273  \n",
       "290       특정범죄가중처벌등에관한법률위반(도주차량, 인정된 죄명 : 교통사고처리특례법위반)      96도591  \n",
       "90   특정범죄가중처벌등에관한법률위반(도주차량, 인정된 죄명 : 교통사고처리특례법위반)·도...     99도5023  \n",
       "287                                        교통사고처리특례법위반     97도1702  \n",
       "293                                        교통사고처리특례법위반     98도2605  \n",
       "129                             교통사고처리특례법위반ㆍ업무상과실자동차파괴     83도3006  \n",
       "76   사기·교통사고처리특례법위반·유가증권위조(변경된죄명:유가증권변조)·위조유가증권행사(변...    2005노396  \n",
       "281  살인·폭력행위등처벌에관한법률위반·특수공무집행방해치상·공용물건손상·도로교통법위반·향정...     96도2588  \n",
       "57                           교통사고처리특례법위반·도로교통법위반(음주운전)   2006노1642  \n",
       "286                                교통사고처리특례법위반·도로교통법위반     96도1540  \n",
       "310                                        교통사고처리특례법위반      92도934  \n",
       "52   폭력행위등처벌에관한법률위반(야간·공동상해)·공무집행방해·교통사고처리특례법위반·도로교...   2004고단232  \n",
       "87                                         교통사고처리특례법위반    2007노187  \n",
       "60                                     교통사고처리특례법위반피고사건       84노95  \n",
       "332                                        교통사고처리특례법위반   2008노6114  \n",
       "29   특정범죄가중처벌등에관한법률위반(도주차량)(인정된 죄명 : 교통사고처리특례법위반)·도...   2000노1145  \n",
       "275                                        교통사고처리특례법위반     96도1198  \n",
       "53                                 교통사고처리특례법위반·도로교통법위반  2004고정1480  \n",
       "358                                    교통 사고 처리 특례법 위반   2011노2629  \n",
       "221                                        교통사고처리특례법위반      89도377  \n",
       "346                                     교통사고 처리 특례법 위반    2011노938  \n",
       "..                                                 ...         ...  \n",
       "25                                         교통사고처리특례법위반     92도2077  \n",
       "204                                        교통사고처리특례법위반              \n",
       "175                                        교통사고처리특례법위반      86도325  \n",
       "238                                        교통사고처리특례법위반      90도761  \n",
       "203                                        교통사고처리특례법위반     87도2173  \n",
       "343                                     교통사고 처리 특례법 위반   2011도3970  \n",
       "149                                        교통사고처리특례법위반     84도2651  \n",
       "207                                        교통사고처리특례법위반      88도632  \n",
       "194                                        교통사고처리특례법위반     86도2514  \n",
       "273                                        교통사고처리특례법위반      96도690  \n",
       "54                           도로교통법위반(음주운전)·교통사고처리특례법위반   2005고정765  \n",
       "5             교통사고처리특례법위반·도로교통법위반(음주운전)·도로교통법위반(무면허운전)  2013도15031  \n",
       "222                                교통사고처리특례법위반,도로교통법위반     89도1792  \n",
       "242                                        교통사고처리특례법위반     90도2000  \n",
       "84                                         교통사고처리특례법위반    2005고단20  \n",
       "130                                        교통사고처리특례법위반      84도182  \n",
       "223                                  중대한교통사고차량면허취소처분취소     89누3564  \n",
       "225                                        교통사고처리특례법위반     89도1696  \n",
       "19                                         교통사고처리특례법위반     88도2010  \n",
       "211                 특정범죄가중처벌등에관한법률위반(도주차량),교통사고처리특례법위반     88도1399  \n",
       "7                        도로교통법위반(사고후미조치)·도로교통법위반(음주운전)  2015도12451  \n",
       "177                                        교통사고처리특례법위반     85도1996  \n",
       "321  특정범죄가중처벌등에관한법률위반(위험운전치사상)(인정된죄명:교통사고처리특례법위반)·도...     2009고정2  \n",
       "102                                        교통사고처리특례법위반   2003도1895  \n",
       "191                                        교통사고처리특례법위반     86도1868  \n",
       "193                                        교통사고처리특례법위반     85도1977  \n",
       "48                                         교통사고처리특례법위반   2007도1808  \n",
       "56                                         교통사고처리특례법위반  2006고정4418  \n",
       "62                                    교통사고처리특례법위반등피고사건    84고단1070  \n",
       "311                                교통사고처리특례법위반,도로교통법위반     92도1602  \n",
       "\n",
       "[375 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_df_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 나온 벡터값이 높은 단어 상위 20개를 활용하여, 각 판례에 20개의 단어 들어있는 갯수대로 카운트를 매겼습니다.\n",
    "위에 가정한대로 카운트 값이 높을수록 해당 판례가 가장 입력값과 연관성이 높은 판례라고 생각했습니다.\n",
    "위에서 확보해놓은 각 판례의 {단어: 갯수}딕셔너리를 통하여 카운트 값이 가장 큰 값 순으로 정렬하였습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_kernel",
   "language": "python",
   "name": "ai_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
